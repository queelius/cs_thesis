use n secrets per word

    for j <- 0 to n-1
        hash(w[i] | secret[j])

or, to provide more pattern obfuscation:

    number of variations generated by below function:

        size(secrets)! / ((size(secrets) - min)! + (size(secrets) - min + 1)!
            + ... + (size(secrets) - get_min(max, size(secrets))))!

        it's just a simple sum over permutations selected from a set of size
        size(secrets) from min selections to max selections.

        n! * sum { i <- min to max 1/(n-i)! }

    generate_permuted_k(term, secrets, depth, min=0, max=infinity)
        if empty(secrets) or depth > max
            return null

        terms = empty set
        for secret in secrets
            new_term = term | secret
            if depth >= min
                add(new_term, terms)

            secrets_left = secrets - {secret}
            generate_permuted(new_term, fewer_secrets, depth+1, min, max)


    size(secrets) * (size(secrets)^size(secrets) - 1) / (size(secrets) - 1)

    --> n * (n^n - 1) / (n - 1)

    e.g., if n=2 secrets -> 2(2^2-1)/1 = 6
        hash(w[i] | secret[0])
        hash(w[i] | secret[1])
        hash(w[i] | secret[0] | secret[0])
        hash(w[i] | secret[0] | secret[1])
        hash(w[i] | secret[1] | secret[0])
        hash(w[i] | secret[1] | secret[1])

    e.g., if n=3 secrets -> 3*(3^3-1)/2 = 39

    or even more; assuming 2 secrets:

        hash(w[i] | secret[i] | secret[j] | ... | secret[z])
        i, j, ..., z in { 0, 1 }
        --> 2^(# of secrets) --> n^m, m in [n, infinity)





bloom filter for types weighted keywords










separate MAS's for wildcard/fuzzy searching. e.g., for fuzzy/wildcard searching,
don't bother with multiplicities. automatic degradation in score.

may add non-fuzzy matches in another set.

